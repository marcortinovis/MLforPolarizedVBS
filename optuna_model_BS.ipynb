{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, RocCurveDisplay\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(529663, 33)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('processed_ntuples\\chunk_data.npy')\n",
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenght of training set 397247 \n",
      "lenght of validation set 132416 \n",
      "width of the sets: # of features + 1 flag (1-LL/0-TX) 33\n"
     ]
    }
   ],
   "source": [
    "train, val = train_test_split(data, random_state=137) # setting the seed for reproducibility; the default train/test split is 0.75/0.25\n",
    "print('lenght of training set', len(train), '\\nlenght of validation set', len(val), '\\nwidth of the sets: # of features + 1 flag (1-LL/0-TX)', len(train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n"
     ]
    }
   ],
   "source": [
    "# strip the last feature (e.g. the flag) from the sets\n",
    "\n",
    "# copy in dedicated arrays\n",
    "flags_train = train[:, -1]\n",
    "flags_val = val[:, -1]\n",
    "# delete from the sets\n",
    "train = train[:, :-1]\n",
    "val = val[:, :-1]\n",
    "# width check\n",
    "print(len(train[0]), len(val[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorize the data, so that pytorch doesn't whine\n",
    "train = torch.tensor(train, dtype=torch.float32)\n",
    "val = torch.tensor(val, dtype=torch.float32)\n",
    "flags_train = torch.tensor(flags_train, dtype=torch.float32)\n",
    "flags_val = torch.tensor(flags_val, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0.01):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        score = -validation_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.best_score= validation_loss\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 22:08:02,759] A new study created in memory with name: no-name-85ba4237-9c1f-4ea0-8487-30f91ae07771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 22:08:55,198] Trial 0 finished with value: 0.7140300273895264 and parameters: {'n_layers': 3, 'batch_size': 2953, 'n_units_l0': 72, 'n_units_l1': 68, 'n_units_l2': 41, 'lr': 0.00013109046372193687}. Best is trial 0 with value: 0.7140300273895264.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped at epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 22:09:41,863] Trial 1 finished with value: 0.7483989596366882 and parameters: {'n_layers': 2, 'batch_size': 1634, 'n_units_l0': 82, 'n_units_l1': 88, 'lr': 0.0009492902754184888}. Best is trial 1 with value: 0.7483989596366882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped at epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 22:11:57,446] Trial 2 finished with value: 0.8407896161079407 and parameters: {'n_layers': 4, 'batch_size': 1661, 'n_units_l0': 95, 'n_units_l1': 86, 'n_units_l2': 48, 'n_units_l3': 97, 'lr': 0.012474626857095059}. Best is trial 2 with value: 0.8407896161079407.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped at epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 22:13:01,465] Trial 3 finished with value: 0.7907956838607788 and parameters: {'n_layers': 2, 'batch_size': 4076, 'n_units_l0': 79, 'n_units_l1': 85, 'lr': 0.01176707924286304}. Best is trial 2 with value: 0.8407896161079407.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped at epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 22:14:00,274] Trial 4 finished with value: 0.7389288544654846 and parameters: {'n_layers': 3, 'batch_size': 790, 'n_units_l0': 46, 'n_units_l1': 56, 'n_units_l2': 91, 'lr': 0.09819628845027825}. Best is trial 2 with value: 0.8407896161079407.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped at epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 22:14:54,209] Trial 5 pruned. \n",
      "[I 2025-03-06 22:14:59,532] Trial 6 pruned. \n",
      "[I 2025-03-06 22:15:09,200] Trial 7 pruned. \n",
      "[I 2025-03-06 22:15:18,262] Trial 8 pruned. \n",
      "[I 2025-03-06 22:16:30,432] Trial 9 pruned. \n",
      "[I 2025-03-06 22:26:20,615] Trial 10 finished with value: 0.7471831440925598 and parameters: {'n_layers': 4, 'batch_size': 59, 'n_units_l0': 91, 'n_units_l1': 68, 'n_units_l2': 47, 'n_units_l3': 97, 'lr': 0.020548641242396564}. Best is trial 2 with value: 0.8407896161079407.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped at epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 22:28:05,378] Trial 11 pruned. \n",
      "[I 2025-03-06 22:28:59,815] Trial 12 pruned. \n",
      "[I 2025-03-06 22:29:10,109] Trial 13 pruned. \n",
      "[I 2025-03-06 22:30:20,548] Trial 14 pruned. \n",
      "[I 2025-03-06 22:30:26,589] Trial 15 pruned. \n",
      "[I 2025-03-06 22:31:46,435] Trial 16 pruned. \n",
      "[I 2025-03-06 22:33:50,754] Trial 17 finished with value: 0.8629772663116455 and parameters: {'n_layers': 2, 'batch_size': 4325, 'n_units_l0': 77, 'n_units_l1': 92, 'lr': 0.0324755063531669}. Best is trial 17 with value: 0.8629772663116455.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped at epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 22:35:09,016] Trial 18 finished with value: 0.7555809020996094 and parameters: {'n_layers': 2, 'batch_size': 412, 'n_units_l0': 65, 'n_units_l1': 93, 'lr': 0.045991625973519155}. Best is trial 17 with value: 0.8629772663116455.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped at epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 22:36:28,470] Trial 19 pruned. \n",
      "[I 2025-03-06 22:36:39,255] Trial 20 pruned. \n",
      "[I 2025-03-06 22:38:02,238] Trial 21 pruned. \n",
      "[I 2025-03-06 22:38:10,382] Trial 22 pruned. \n",
      "[I 2025-03-06 22:38:57,227] Trial 23 pruned. \n",
      "[I 2025-03-06 22:40:09,570] Trial 24 pruned. \n",
      "[I 2025-03-06 22:40:20,412] Trial 25 pruned. \n",
      "[I 2025-03-06 22:41:13,508] Trial 26 pruned. \n",
      "[I 2025-03-06 22:41:22,978] Trial 27 pruned. \n",
      "[I 2025-03-06 22:41:29,047] Trial 28 pruned. \n",
      "[I 2025-03-06 22:41:39,239] Trial 29 pruned. \n",
      "[I 2025-03-06 22:42:55,099] Trial 30 pruned. \n",
      "[I 2025-03-06 22:43:07,367] Trial 31 pruned. \n",
      "[I 2025-03-06 22:44:17,452] Trial 32 pruned. \n",
      "[I 2025-03-06 22:44:22,881] Trial 33 pruned. \n",
      "[I 2025-03-06 22:45:35,801] Trial 34 finished with value: 0.7748686075210571 and parameters: {'n_layers': 3, 'batch_size': 584, 'n_units_l0': 70, 'n_units_l1': 86, 'n_units_l2': 52, 'lr': 0.007542610062398562}. Best is trial 17 with value: 0.8629772663116455.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped at epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 22:46:45,906] Trial 35 pruned. \n",
      "[I 2025-03-06 22:46:53,402] Trial 36 pruned. \n",
      "[I 2025-03-06 22:47:44,383] Trial 37 finished with value: 0.7753443717956543 and parameters: {'n_layers': 3, 'batch_size': 2071, 'n_units_l0': 86, 'n_units_l1': 80, 'n_units_l2': 57, 'lr': 0.020074591109019418}. Best is trial 17 with value: 0.8629772663116455.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped at epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 22:48:43,831] Trial 38 pruned. \n",
      "[I 2025-03-06 22:48:53,842] Trial 39 pruned. \n",
      "[I 2025-03-06 22:49:58,430] Trial 40 pruned. \n",
      "[I 2025-03-06 22:51:00,916] Trial 41 pruned. \n",
      "[I 2025-03-06 22:52:01,223] Trial 42 pruned. \n",
      "[I 2025-03-06 22:53:28,768] Trial 43 pruned. \n",
      "[I 2025-03-06 22:53:37,765] Trial 44 pruned. \n",
      "[I 2025-03-06 22:54:37,306] Trial 45 pruned. \n",
      "[I 2025-03-06 22:54:45,040] Trial 46 pruned. \n",
      "[I 2025-03-06 22:54:53,095] Trial 47 pruned. \n",
      "[I 2025-03-06 22:55:04,588] Trial 48 pruned. \n",
      "[I 2025-03-06 22:55:10,383] Trial 49 pruned. \n",
      "[I 2025-03-06 22:56:23,251] Trial 50 pruned. \n",
      "[I 2025-03-06 22:56:47,858] Trial 51 pruned. \n",
      "[I 2025-03-06 22:57:24,278] Trial 52 pruned. \n",
      "[I 2025-03-06 22:57:31,154] Trial 53 pruned. \n",
      "[I 2025-03-06 22:58:40,998] Trial 54 pruned. \n",
      "[I 2025-03-06 22:59:42,283] Trial 55 pruned. \n",
      "[I 2025-03-06 22:59:48,418] Trial 56 pruned. \n",
      "[I 2025-03-06 23:00:46,980] Trial 57 pruned. \n",
      "[I 2025-03-06 23:00:55,651] Trial 58 pruned. \n",
      "[I 2025-03-06 23:02:01,040] Trial 59 pruned. \n",
      "[I 2025-03-06 23:02:10,040] Trial 60 pruned. \n",
      "[I 2025-03-06 23:02:16,296] Trial 61 pruned. \n",
      "[I 2025-03-06 23:02:22,803] Trial 62 pruned. \n",
      "[I 2025-03-06 23:03:59,601] Trial 63 finished with value: 0.8652051091194153 and parameters: {'n_layers': 2, 'batch_size': 2036, 'n_units_l0': 98, 'n_units_l1': 91, 'lr': 0.00965812692572207}. Best is trial 63 with value: 0.8652051091194153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped at epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 23:05:04,802] Trial 64 pruned. \n",
      "[I 2025-03-06 23:06:08,132] Trial 65 pruned. \n",
      "[I 2025-03-06 23:07:23,768] Trial 66 pruned. \n",
      "[I 2025-03-06 23:07:45,477] Trial 67 pruned. \n",
      "[I 2025-03-06 23:07:56,252] Trial 68 pruned. \n",
      "[I 2025-03-06 23:08:05,961] Trial 69 pruned. \n",
      "[I 2025-03-06 23:08:38,848] Trial 70 pruned. \n",
      "[I 2025-03-06 23:08:45,833] Trial 71 pruned. \n",
      "[I 2025-03-06 23:09:31,843] Trial 72 pruned. \n",
      "[I 2025-03-06 23:09:38,241] Trial 73 pruned. \n",
      "[I 2025-03-06 23:10:04,189] Trial 74 pruned. \n",
      "[I 2025-03-06 23:10:43,398] Trial 75 pruned. \n",
      "[I 2025-03-06 23:10:49,717] Trial 76 pruned. \n",
      "[I 2025-03-06 23:10:56,080] Trial 77 pruned. \n",
      "[I 2025-03-06 23:11:03,875] Trial 78 pruned. \n",
      "[I 2025-03-06 23:12:10,836] Trial 79 pruned. \n",
      "[I 2025-03-06 23:12:22,544] Trial 80 pruned. \n",
      "[I 2025-03-06 23:13:11,159] Trial 81 pruned. \n",
      "[I 2025-03-06 23:13:49,080] Trial 82 pruned. \n",
      "[I 2025-03-06 23:14:06,365] Trial 83 pruned. \n",
      "[I 2025-03-06 23:14:16,014] Trial 84 pruned. \n",
      "[I 2025-03-06 23:15:15,439] Trial 85 pruned. \n",
      "[I 2025-03-06 23:16:21,328] Trial 86 pruned. \n",
      "[I 2025-03-06 23:16:35,409] Trial 87 pruned. \n",
      "[I 2025-03-06 23:16:44,757] Trial 88 pruned. \n",
      "[I 2025-03-06 23:16:51,074] Trial 89 pruned. \n",
      "[I 2025-03-06 23:16:59,651] Trial 90 pruned. \n",
      "[I 2025-03-06 23:17:08,584] Trial 91 pruned. \n",
      "[I 2025-03-06 23:17:18,002] Trial 92 pruned. \n",
      "[I 2025-03-06 23:18:56,681] Trial 93 pruned. \n",
      "[I 2025-03-06 23:19:19,275] Trial 94 pruned. \n",
      "[I 2025-03-06 23:19:27,278] Trial 95 pruned. \n",
      "[I 2025-03-06 23:19:37,805] Trial 96 pruned. \n",
      "[I 2025-03-06 23:20:01,243] Trial 97 pruned. \n",
      "[I 2025-03-06 23:20:49,258] Trial 98 finished with value: 0.8067454099655151 and parameters: {'n_layers': 2, 'batch_size': 2235, 'n_units_l0': 98, 'n_units_l1': 50, 'lr': 0.05632672456019568}. Best is trial 63 with value: 0.8652051091194153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped at epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 23:21:30,887] Trial 99 pruned. \n"
     ]
    }
   ],
   "source": [
    "# 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "\n",
    "    n_epochs = 50\n",
    "\n",
    "    loss_function = nn.BCELoss() # CrossEntropyLoss but for just one class\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(patience=5, delta=0.01)\n",
    "\n",
    "    # 2. Suggest values of the hyperparameters using a trial object.\n",
    "    n_layers = trial.suggest_int('n_layers', 2, 4)\n",
    "    layers = []\n",
    "\n",
    "    batch_size = trial.suggest_int('batch_size', 50, 5000)\n",
    "    batch_start = torch.arange(0, len(train), batch_size)\n",
    "\n",
    "    in_features = len(train[0])\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(f'n_units_l{i}', 40, 100)\n",
    "        layers.append(torch.nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.BatchNorm1d(out_features))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        layers.append(torch.nn.Dropout(0.25))\n",
    "        in_features = out_features\n",
    "    layers.append(torch.nn.Linear(in_features, 1))\n",
    "    layers.append(nn.Sigmoid())\n",
    "    model = torch.nn.Sequential(*layers).to(torch.device('cpu'))\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-1, log=True)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        with tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "            bar.set_description(f\"Epoch {epoch}\")\n",
    "            for start in bar:\n",
    "                # take a batch\n",
    "                train_batch = train[start:start+batch_size]\n",
    "                flags_train_batch = flags_train[start:start+batch_size]\n",
    "                # forward pass\n",
    "                outputs = model(train_batch)\n",
    "                loss = loss_function(outputs, flags_train_batch.unsqueeze(0).T)\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # update weights\n",
    "                optimizer.step()\n",
    "                # print progress\n",
    "                acc = (outputs.round() == flags_train_batch).float().mean()\n",
    "                bar.set_postfix(\n",
    "                    loss=float(loss),\n",
    "                    acc=float(acc)\n",
    "                )\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(val)\n",
    "            val_loss = loss_function(val_outputs, flags_val.unsqueeze(0).T)\n",
    "            accuracy = float((val_outputs.round().T == flags_val).float().mean())\n",
    "\n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "        # Early Stopping\n",
    "        if early_stopping.early_stop(val_loss):\n",
    "            print(f'Early stopped at epoch: {epoch}')\n",
    "            break\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=5, delta=0.01)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value:  0.8652051091194153\n",
      "  Params: \n",
      "    n_layers: 2\n",
      "    batch_size: 2036\n",
      "    n_units_l0: 98\n",
      "    n_units_l1: 91\n",
      "    lr: 0.00965812692572207\n"
     ]
    }
   ],
   "source": [
    "print(\"Best trial:\")\n",
    "b_trial = study.best_trial\n",
    "print(\"  Value: \", b_trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in b_trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    n_layers: 2\n",
      "    batch_size: 2036\n",
      "    n_units_l0: 98\n",
      "    n_units_l1: 91\n",
      "    lr: 0.00965812692572207\n"
     ]
    }
   ],
   "source": [
    "file = open('optuna_res_BS.txt', 'w')\n",
    "\n",
    "for key, value in b_trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "    file.write(\"    {}: {}\\n\".format(key, value))\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
